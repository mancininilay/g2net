{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Package","metadata":{}},{"cell_type":"code","source":"!pip install nnAudio\n!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:16:30.335469Z","iopub.execute_input":"2022-04-12T08:16:30.336103Z","iopub.status.idle":"2022-04-12T08:16:48.485256Z","shell.execute_reply.started":"2022-04-12T08:16:30.336001Z","shell.execute_reply":"2022-04-12T08:16:48.484374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:16:57.875771Z","iopub.execute_input":"2022-04-12T08:16:57.876589Z","iopub.status.idle":"2022-04-12T08:16:57.882111Z","shell.execute_reply.started":"2022-04-12T08:16:57.876534Z","shell.execute_reply":"2022-04-12T08:16:57.880738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nimport torch\nimport math\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras import Sequential, utils, optimizers, metrics\nimport tensorflow.keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nfrom random import shuffle\nfrom nnAudio.Spectrogram import CQT1992v2\nfrom scipy import signal, fft\nfrom efficientnet.tfkeras import EfficientNetB0, EfficientNetB1\nfrom scipy.interpolate import interp1d\nfrom scipy.signal import butter, lfilter\n\nTOP_INPUT_DIRECTORY = \"../input/g2net-gravitational-wave-detection\"\nBATCH_SIZE = 256\nEPOCHS = 1\nEXAMPLE_IDENTIFIER_1 = \"00000e74ad\"\nEXAMPLE_IDENTIFIER_0 = \"00001f4945\"\nRANDOM_SAMPLE_SIZE = 1\nPERFORM_FITTING = True\nSAMPLING_FREQUENCY = 2048\nSAMPLES_1 = 4096\nSAMPLES_3 = 3 * SAMPLES_1\nUSE_TRAIN_SUBSET = False\nUSE_TEST_SUBSET = False\nSUBSET_SIZE = 1024\nLEARNING_RATE = 0.001\nTRAIN_TEST_SPLIT = 0.95\n\n\n# Utility functions\n\ndef make_array_cyclic(array):\n    \"\"\"Takes as input a 2d ndarray, and returns the same array but with the last\n    array copied to the front (so array [[0], [1], [2]] -> [[2], [0], [1], [2]]\n    This is so convolution layers can identify features between measurements by\n    sensors 0 and 2.\"\"\"\n    last_array = array[-1, :]\n    reshaped_array = np.reshape(last_array, (1, last_array.shape[0]))\n    # print(reshaped_array.shape)\n    return np.insert(array, 0, reshaped_array, 0)\n\n\ndef get_array(identifier, is_training=True):\n    \"\"\"Eg. Given identifier \"00001f4945\", returns array loaded from\n    input/train/0/0/0/00001f4945.npy. If is_training is False, use test instead\n    of train.\"\"\"\n    char0 = identifier[0]\n    char1 = identifier[1]\n    char2 = identifier[2]\n    if is_training:\n        path = f\"{TOP_INPUT_DIRECTORY}/train/{char0}/{char1}/{char2}/{identifier}.npy\"\n    else:\n        path = f\"{TOP_INPUT_DIRECTORY}/test/{char0}/{char1}/{char2}/{identifier}.npy\"\n    return np.load(path)\n\ndef get_array_n(identifier, is_training=True):\n    \"\"\"Return hstack of signal, each signal normalised before stack.\"\"\"\n    arr = get_array(identifier, is_training)\n    arr0 = arr[0]\n    arr0 = arr0 / np.max(arr0)\n    arr1 = arr[1]\n    arr1 = arr1 / np.max(arr1)\n    arr2 = arr[2]\n    arr2 = arr2 / np.max(arr2)\n    return np.hstack([arr0, arr1, arr2])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:16:57.886532Z","iopub.execute_input":"2022-04-12T08:16:57.88711Z","iopub.status.idle":"2022-04-12T08:17:05.240927Z","shell.execute_reply.started":"2022-04-12T08:16:57.887066Z","shell.execute_reply":"2022-04-12T08:17:05.240079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data visualisation","metadata":{}},{"cell_type":"code","source":"targets = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}/training_labels.csv\")\ny = targets[\"target\"].values\n\nall_identifiers = targets[\"id\"].values\nidentifiers_1 = targets[targets[\"target\"] == 1][\"id\"].values\nidentifiers_0 = targets[targets[\"target\"] == 0][\"id\"].values\n\n# Choose a random few samples with signal and no-signal.\nsample_ids_1 = np.random.choice(identifiers_1, RANDOM_SAMPLE_SIZE)\nprint(f\"\\nRandom samples with SIGNAL + NOISE: {sample_ids_1}\")\nsample_ids_0 = np.random.choice(identifiers_0, RANDOM_SAMPLE_SIZE)\nprint(f\"\\nRandom samples with ONLY NOISE: {sample_ids_0}\")\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:05.242576Z","iopub.execute_input":"2022-04-12T08:17:05.242865Z","iopub.status.idle":"2022-04-12T08:17:05.662183Z","shell.execute_reply.started":"2022-04-12T08:17:05.242825Z","shell.execute_reply":"2022-04-12T08:17:05.661368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for id in sample_ids_1:\n    data = get_array(id,True)\n    plt.figure(figsize=(20,5))\n    plt.plot(data[0], color=\"red\", label=\"Hanford Data\")\n    plt.plot(data[1], color=\"green\", label=\"Livingston Data\")\n    plt.plot(data[2], color=\"blue\", label=\"Virgo Data\")\n    plt.xlabel(\"sample\")\n    plt.ylabel(\"strain (m)\")\n    plt.legend()\n    plt.title(f\" Data of each detector for {id} : Noise + signal\")\n\nfor id in sample_ids_0:\n    data = get_array(id,True)\n    plt.figure(figsize=(20,5))\n    plt.plot(data[0], color=\"red\", label=\"Hanford Data\")\n    plt.plot(data[1], color=\"green\", label=\"Livingston Data\")\n    plt.plot(data[2], color=\"blue\", label=\"Virgo Data\")\n    plt.xlabel(\"sample\")\n    plt.ylabel(\"strain (m)\")\n    plt.legend()\n    plt.title(f\"Data of each detector for {id} : Noise\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:05.66351Z","iopub.execute_input":"2022-04-12T08:17:05.663788Z","iopub.status.idle":"2022-04-12T08:17:06.5755Z","shell.execute_reply.started":"2022-04-12T08:17:05.663742Z","shell.execute_reply":"2022-04-12T08:17:06.574713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cqt_spectrogram(id, is_train=True):\n    cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, hop_length=64, fmin=20, fmax=1024, bins_per_octave=12, norm=1, window='hann', center=True, pad_mode='reflect', trainable=False, output_format='Magnitude', verbose=False)\n#     cqt = CQT1992v2(sr=SAMPLING_FREQUENCY, fmin=20, fmax=1024, hop_length=64)\n    waveform = np.hstack(get_array(id, is_train))\n#     waveform = get_array_n(id, is_train)\n    waveform = waveform / np.max(waveform)\n    waveform = torch.from_numpy(waveform).float()\n    cqt_image = cqt(waveform)\n    cqt_image = np.array(cqt_image)\n#     cqt_image = np.squeeze(cqt_image, axis=0)\n    cqt_image = np.transpose(cqt_image, (1,2,0))\n    return cqt_image\n\ndef plot_cqt_spectrogram(id, is_train=True):\n    image = get_cqt_spectrogram(id, is_train)\n    plt.figure(figsize=(20,5))\n    plt.imshow(image)\n    plt.xlabel(\"scaled time\")\n    plt.ylabel(\"scaled frequency\")\n    plt.title(f\"CQT1992 (nnAudio) spectrogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n\ncqt_image = get_cqt_spectrogram(EXAMPLE_IDENTIFIER_1)\nprint(\"\")\nprint(f\"nnAudio CQT1992 spectrogram shape: {cqt_image.shape}\")\nprint(\"\")\n\nfor id in sample_ids_1:\n    plot_cqt_spectrogram(id)\n    \nfor id in sample_ids_0:\n    plot_cqt_spectrogram(id)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:06.580468Z","iopub.execute_input":"2022-04-12T08:17:06.582667Z","iopub.status.idle":"2022-04-12T08:17:07.64619Z","shell.execute_reply.started":"2022-04-12T08:17:06.580893Z","shell.execute_reply":"2022-04-12T08:17:07.645379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scipy_spectrogram(id, is_train=True):\n    # Careful using in batch loader, as freq/time axes values are returned also - repeated and complete waste.\n    waveform = np.hstack(get_array(id))\n    waveform = waveform / np.max(waveform)\n    (freq, time, intensity) = signal.spectrogram(waveform, SAMPLING_FREQUENCY, mode=\"magnitude\", scaling=\"spectrum\", window=('kaiser', 14))\n    return (freq, time, intensity)\n\ndef plot_scipy_spectrogram(id, is_train=True):\n    (f, t, i) = get_scipy_spectrogram(id, is_train)\n    plt.figure(figsize=(20,5))\n    plt.pcolormesh(t, f, i, shading='gouraud')\n    plt.ylabel('Frequency [Hz]')\n    plt.xlabel('Time [sec]')\n    plt.ylim(0,100)\n    plt.title(f\"Scipy spectrogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.show()\n    \nfor id in sample_ids_1:\n    plot_scipy_spectrogram(id)\n    \nfor id in sample_ids_0:\n    plot_scipy_spectrogram(id)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:07.647719Z","iopub.execute_input":"2022-04-12T08:17:07.647971Z","iopub.status.idle":"2022-04-12T08:17:08.70589Z","shell.execute_reply.started":"2022-04-12T08:17:07.647937Z","shell.execute_reply":"2022-04-12T08:17:08.705179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scipy_fft(id, is_train=True):\n    waveform = np.hstack(get_array(id))\n#     window = signal.kaiser(SAMPLES_3, 14)\n#     window = signal.blackman(SAMPLES_3)\n    window = signal.hann(SAMPLES_3)\n    return np.abs(fft.rfft(waveform * window))\n\ndef plot_scipy_fft(id, is_train=True):\n    fast = get_scipy_fft(id)\n    xf = fft.rfftfreq(SAMPLES_3, 1 / SAMPLING_FREQUENCY)\n    plt.figure(figsize=(20,5))\n#     plt.xlim(100, 300)\n    plt.yscale(\"log\")\n    plt.xlabel('frequency [Hz]')\n    plt.ylabel('Relative Amplitude')\n    plt.title(f\"Scipy rfft of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.plot(xf, fast)\n\nfor id in sample_ids_1:\n    plot_scipy_fft(id)\n    \nfor id in sample_ids_0:\n    plot_scipy_fft(id)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:08.707159Z","iopub.execute_input":"2022-04-12T08:17:08.707524Z","iopub.status.idle":"2022-04-12T08:17:10.352929Z","shell.execute_reply.started":"2022-04-12T08:17:08.707489Z","shell.execute_reply":"2022-04-12T08:17:10.352151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_welch_periodogram(id, is_train=True):\n    f, Pxx_den = signal.welch(np.hstack(get_array(id)), SAMPLING_FREQUENCY, nperseg=1024)\n    return f, Pxx_den\n\ndef plot_welch_periodogram(id, is_train=True):\n    f, Pxx_den = get_welch_periodogram(id)\n    plt.figure(figsize=(20,5))\n    plt.semilogy(f, Pxx_den)\n    # plt.ylim([0.5e-3, 1])\n    plt.xlabel('frequency [Hz]')\n    plt.ylabel('PSD [V**2/Hz]')\n    plt.title(f\"Scipy welch periodogram of hstack'd data {id} - {targets[targets['id'] == id].target.values}\")\n    plt.show()\n\nfor id in sample_ids_1:\n    plot_welch_periodogram(id)\n    \nfor id in sample_ids_0:\n    plot_welch_periodogram(id)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:10.354266Z","iopub.execute_input":"2022-04-12T08:17:10.354649Z","iopub.status.idle":"2022-04-12T08:17:11.691304Z","shell.execute_reply.started":"2022-04-12T08:17:10.354611Z","shell.execute_reply":"2022-04-12T08:17:11.690579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Model definition","metadata":{}},{"cell_type":"code","source":"# Shapes of some of the data considered.\n\narr = get_array(EXAMPLE_IDENTIFIER_1)\nprint(\"\\n\")\nprint(f\"Shape of array.shape: {arr.shape}\")\nprint(f\"Shape of array[0].shape: {arr[0].shape}\")\nprint(f\"Shape of np.hstack(array).shape: {np.hstack(arr).shape}\")\nprint(f\"Shape of np.vstack(array).shape: {np.vstack(arr).shape}\")\nprint(\"\\n\")\n(f, t, i) = get_scipy_spectrogram(EXAMPLE_IDENTIFIER_1)\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) time (t of f,t,i): {t.shape}\")\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) frequency (f of f,t,i): {f.shape}\")\nprint(f\"Shape of scipy spectrogram (get_scipy_spectrogram) intensity (i=(f,t) of f,t,i): {i.shape}\")\nprint(f\"Shape of nnAudio CQT1992 spectrogram (get_cqt_spectrogram) (t, f): {get_cqt_spectrogram(EXAMPLE_IDENTIFIER_1).shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.692528Z","iopub.execute_input":"2022-04-12T08:17:11.692873Z","iopub.status.idle":"2022-04-12T08:17:11.726859Z","shell.execute_reply.started":"2022-04-12T08:17:11.692834Z","shell.execute_reply":"2022-04-12T08:17:11.726052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General Dataset generator, to be extended with specific implementations of fetching sample/batch\n\nclass DataSetGenerator(Sequence):\n    \"\"\"Allows batch-loading of the ~50GB training data so we don't exhaust RAM.\"\"\"\n\n    def get_sample(self, id, is_train):\n        \"\"\"Needs to be implemented by child.\"\"\"\n        pass\n    \n    def __init__(self, identifiers, y=None, batch_size=256,\n        shuffle=True, no_channels=1, no_classes=10, name=\"Unknown DataSet\"):\n        \"\"\"Provided custom parameters for DataGenerator. At minimum, input an array\n        of identifiers. If training, input the targets values also.\"\"\"\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.identifiers = identifiers\n        self.y = y\n        self.name = name\n        if y is not None:\n            self.is_training = True\n        else:\n            self.is_training = False\n        self.shape = self.get_sample(self.identifiers[0], self.is_training).shape\n        print(f\"{self.name} - Shape of each sample: {self.shape}\\n\")\n#         self.on_epoch_end()\n\n    def __len__(self):\n        \"\"\"States number of batches per epoch (rounds up).\"\"\"\n#         return int(np.ceil(len(self.identifiers) / self.batch_size))\n        return math.ceil(len(self.identifiers)/self.batch_size)\n\n    def __getitem__(self, index):\n        \"\"\"Return batch of X (and y if training). Can be overidden in child if model input shape requires.\"\"\"\n        batch_ids = self.identifiers[index * self.batch_size:(index + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n        \n        # batch_X = np.array([get_array(x, self.is_training) for x in batch_ids])\n        list_x = np.array([self.get_sample(x, self.is_training) for x in batch_ids])\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        batch_X = np.stack(list_x)\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        # batch_X = np.stack(list_x)\n        if self.is_training:\n            return batch_X, batch_y\n        else:\n            return batch_X\n\n    def on_epoch_end(self):\n        \"\"\"Shuffle at the end of each epoch.\"\"\"\n        pass\n        if self.shuffle and self.is_training:\n            ids_y = list(zip(self.identifiers, self.y))\n            shuffle(ids_y)\n            self.identifiers, self.y = list(zip(*ids_y))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.72818Z","iopub.execute_input":"2022-04-12T08:17:11.728448Z","iopub.status.idle":"2022-04-12T08:17:11.742357Z","shell.execute_reply.started":"2022-04-12T08:17:11.72841Z","shell.execute_reply":"2022-04-12T08:17:11.741172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TimeSeriesDataSetGenerator(DataSetGenerator):\n    \"\"\"Inherits from DataSetGenerator class, methods to get sample and therefore batch are implemented, simply\n    fetching the raw samples of 3x4096 ndarrays.\"\"\"\n    \n    def get_sample(self, id, is_train):\n        \"\"\"Return 3x4096 ndarray (time-series data).\"\"\"\n        return make_array_cyclic(get_array(id, is_train))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.746091Z","iopub.execute_input":"2022-04-12T08:17:11.746717Z","iopub.status.idle":"2022-04-12T08:17:11.754126Z","shell.execute_reply.started":"2022-04-12T08:17:11.746653Z","shell.execute_reply":"2022-04-12T08:17:11.752778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Cqt1992DataSetGenerator(DataSetGenerator):\n    \"\"\"Inherits from DataSetGenerator class, methods to get sample and therefore batch are implemented, fetches\n    CQT1992 spectrogram of the hstack'd arrays.\"\"\"\n    \n    def get_sample(self, id, is_train):\n        \"\"\"Return CQT1992 spectrogram.\"\"\"\n        return get_cqt_spectrogram(id, is_train)\n    \n    def __getitem__(self, index):\n        \"\"\"Return batch of X (and y if training). Can be overidden in child if model input shape requires.\"\"\"\n        batch_ids = self.identifiers[index * self.batch_size:(index + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n\n        # batch_X = np.array([get_array(x, self.is_training) for x in batch_ids])\n        list_x = np.array([self.get_sample(x, self.is_training) for x in batch_ids])\n        # batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n        batch_X = np.stack(list_x)\n#         batch_X = batch_X.reshape((batch_X.shape[0], batch_X.shape[1], batch_X.shape[2], 1))\n\n        # batch_X = np.stack(list_x)\n        if self.is_training:\n            return batch_X, batch_y\n        else:\n            return batch_X","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.755985Z","iopub.execute_input":"2022-04-12T08:17:11.756346Z","iopub.status.idle":"2022-04-12T08:17:11.766539Z","shell.execute_reply.started":"2022-04-12T08:17:11.756299Z","shell.execute_reply":"2022-04-12T08:17:11.765423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_basic_cnn_model(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n#     # detect and init the TPU\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n#     # instantiate a distribution strategy\n#     tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n#     # instantiating the model in the strategy scope creates the model on the TPU\n#     with tpu_strategy.scope():\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0], shape[1], 1), name=\"Input\"),\n        layers.Conv2D(3, (2,1024), strides=(1,512), padding='same', name=\"Conv2D_1\"),\n        layers.MaxPooling2D(pool_size=(2,4), strides=(1, 2), padding='valid', name=\"MaxPooling_1\"),\n#         layers.Conv2D(64, 3, activation='relu', padding='same', name=\"Conv2D_2\"),\n#         layers.MaxPooling2D(pool_size=(1, 2), strides=(1, 2), padding='valid', name=\"MaxPooling_2\"),\n#         layers.GlobalAveragePooling2D(name=\"GlobalAveragePooling_1\"),\n        layers.Flatten(),\n        layers.Dense(32, activation='relu', name=\"Dense_1\"),\n        layers.Dense(1, activation='sigmoid', name=\"Dense_2\")\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.768701Z","iopub.execute_input":"2022-04-12T08:17:11.769187Z","iopub.status.idle":"2022-04-12T08:17:11.78082Z","shell.execute_reply.started":"2022-04-12T08:17:11.769142Z","shell.execute_reply":"2022-04-12T08:17:11.779911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cqt1992_model(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n    # Build model layers.\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0],shape[1],1)),\n        layers.Conv2D(3,3,activation='relu',padding='same'),\n#         EfficientNetB0(include_top=False,input_shape=(),weights='imagenet'),\n        EfficientNetB1(include_top=False,input_shape=(),weights='imagenet'),\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(32,activation='relu'),\n        layers.Dense(1, activation='sigmoid')\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    \n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    \n    # Compile with specific optimizer / loss / metric.\n    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.782776Z","iopub.execute_input":"2022-04-12T08:17:11.783108Z","iopub.status.idle":"2022-04-12T08:17:11.793237Z","shell.execute_reply.started":"2022-04-12T08:17:11.783065Z","shell.execute_reply":"2022-04-12T08:17:11.792348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_template(shape):\n    \"\"\"Returns compiled model (callbacks, history, fitting etc not done here).\"\"\"\n    # Build model layers.\n    model = Sequential([\n        layers.InputLayer(input_shape=(shape[0], shape[1], 1), name=\"Input\"),\n        layers.Conv2D(3, (2,1024), strides=(1,512), padding='same', name=\"Conv2D_1\"),\n        # layers.BatchNormalization(),\n        # layers.ReLU(),\n        layers.MaxPooling2D(pool_size=(2,4), strides=(1, 2), padding='valid', name=\"MaxPooling_1\"),\n        layers.Flatten(),\n        layers.Dense(32, activation='relu', name=\"Dense_1\"),\n        layers.Dense(1, activation='sigmoid', name=\"Dense_2\")\n        # layers.Dense(1, activation='softmax', name=\"Dense_1\")\n    ])\n    \n    # Print summary of model layers.\n    model.summary()\n    \n    # Draw diagram of model\n    # utils.plot_model(model, to_file=\"model.png\", show_shapes=True)\n    \n    # Compile with specific optimizer / loss / metric.\n#     model.compile(optimizer=optimizers.Adam(learning_rate=0.01),\n    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=[metrics.AUC()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.79494Z","iopub.execute_input":"2022-04-12T08:17:11.795614Z","iopub.status.idle":"2022-04-12T08:17:11.805737Z","shell.execute_reply.started":"2022-04-12T08:17:11.795572Z","shell.execute_reply":"2022-04-12T08:17:11.804963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up DataSetGenerator and get model\n\ntargets = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}/training_labels.csv\")\nsample_submission = pd.read_csv(f\"{TOP_INPUT_DIRECTORY}/sample_submission.csv\")\n\nif USE_TRAIN_SUBSET:\n    targets = targets.sample(SUBSET_SIZE)\n    \nif USE_TEST_SUBSET:\n    sample_submission = sample_submission.sample(SUBSET_SIZE)\n\ntest_identifiers = sample_submission[\"id\"].values\nidentifiers = targets[\"id\"].values\ny = targets[\"target\"].values\n\n# print(identifiers[:5])\n# print(y[:5])\n# print(test_identifiers[:5])\n\ntrain_x, valid_x, train_y, valid_y = train_test_split(identifiers, y, train_size=TRAIN_TEST_SPLIT, random_state=42, stratify=y)\n\n\n\n# train_dataset = TimeSeriesDataSetGenerator(train_x, train_y, batch_size=BATCH_SIZE, name=\"Training\")\n# valid_dataset = TimeSeriesDataSetGenerator(valid_x, valid_y, batch_size=BATCH_SIZE, name=\"Validation\")\n# test_dataset = TimeSeriesDataSetGenerator(test_identifiers, batch_size=BATCH_SIZE, name=\"Test\")\n\ntrain_dataset = Cqt1992DataSetGenerator(train_x, train_y, batch_size=BATCH_SIZE, name=\"Training\")\nvalid_dataset = Cqt1992DataSetGenerator(valid_x, valid_y, batch_size=BATCH_SIZE, name=\"Validation\")\ntest_dataset = Cqt1992DataSetGenerator(test_identifiers, batch_size=BATCH_SIZE, name=\"Test\")\n\nassert train_dataset.shape == valid_dataset.shape == test_dataset.shape\n\n# Get shape from chosen DataSet, and input to model.\nsample_shape = train_dataset.shape\n# print(sample_shape)\nprint(\"\\n\\n\\n\")\nmodel = get_cqt1992_model(sample_shape)\n\n\n\n# Add extras like callbacks to model, and fit.\n\n# Model callbacks/fitting etc specifics\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.001\n    ),\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=1),\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:17:11.807741Z","iopub.execute_input":"2022-04-12T08:17:11.808314Z","iopub.status.idle":"2022-04-12T08:17:21.295312Z","shell.execute_reply.started":"2022-04-12T08:17:11.808253Z","shell.execute_reply":"2022-04-12T08:17:21.294511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PERFORM_FITTING:\n    # Fit model (obtaining history for later plotting).\n#     history = model.fit(\n    model.fit(\n        train_dataset,\n        validation_data=valid_dataset,\n        epochs=EPOCHS,\n    #     callbacks=callbacks,\n        # validation_split=0.2,\n        verbose=1,\n    )","metadata":{"execution":{"iopub.status.busy":"2022-04-12T08:49:24.549312Z","iopub.execute_input":"2022-04-12T08:49:24.5496Z","iopub.status.idle":"2022-04-12T10:29:38.620238Z","shell.execute_reply.started":"2022-04-12T08:49:24.549568Z","shell.execute_reply":"2022-04-12T10:29:38.616289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}